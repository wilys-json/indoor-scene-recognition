{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model\n",
    "\n",
    "***Note: make sure you have [preprocessed](./ENindoor67-Preprocessing.ipynb) images for `efficientnet-b0`***\n",
    "\n",
    "Our benchmark model is a fine-tuned [ResNeXt101_32x16d_WSL](https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/) CNN. This model is replicated from the github repo of [ashrutkumar](https://github.com/ashrutkumar/Indoor-scene-recognition) with the the `softmax` layer replaced by `torch.max` in the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "\n",
    "sys.path.append('../source')\n",
    "session = Session()\n",
    "bucket = session.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 's3://sagemaker-us-east-2-194071253362/mit_indoor_67/processed/test/efficientnet_b0/indoor67_test.pkl',\n",
       " 'train': 's3://sagemaker-us-east-2-194071253362/mit_indoor_67/processed/train/efficientnet_b0',\n",
       " 'val': 's3://sagemaker-us-east-2-194071253362/mit_indoor_67/processed/val/efficientnet_b0'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = '../data/mit_indoor_67/metadata/'\n",
    "efficientnet = 'efficientnet_b0'  # Image size (3,224, 224)\n",
    "metadata_file = root_dir + efficientnet + \".pkl\"\n",
    "metadata = pickle.load(open(metadata_file, 'rb'))\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define output_path, source directory and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model artefacts will be saved to: s3://sagemaker-us-east-2-194071253362/mit_indoor_67\n"
     ]
    }
   ],
   "source": [
    "prefix = 'mit_indoor_67'\n",
    "output_path = os.path.join('s3://', bucket, prefix)\n",
    "print('model artefacts will be saved to: {}'.format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '../source'\n",
    "dependencies = ['../source/dataset', '../source/utils']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: cannot read infile: [Errno 2] No such file or directory: '../source/train.py'\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ../source/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mitindoor67-resnext101-32x16d-2020-11-26-04-10-32\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "job_name = \"mitindoor67-resnext101-32x16d-{}\".format(strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()))\n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set instance details, Pytorch framework version and hyperparameters:\n",
    "\n",
    "The model uses a `torch.optim.SGD` optimizer with `learning_rate` : 0.001, `momentum` of 0.9, and `subsetrandom` sampling. Early stopping was not implemented in the [original script](https://github.com/ashrutkumar/Indoor-scene-recognition/blob/master/indoor_scene_recognition.ipynb) as it claims and hence we will train the model up to 20 epochs initially; if the model converges, we will take it as the benchmark model.\n",
    "\n",
    "The model with the best `val_acc` will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = 'ml.p3.2xlarge'\n",
    "instance_count = 1\n",
    "framework_version = '1.6.0'\n",
    "\n",
    "hyperparameters = {\n",
    "                    'model' : 'ResNext101',  # this will load pretrained ResNeXt101-32x16d_WSL\n",
    "                    'epochs': 20, \n",
    "                    'batch-size' : 50,  # batch size - original model HP\n",
    "                    'sampling' : 'subsetrandom',  # sampling method - original model setting\n",
    "                    'workers' : 7,  # number of workers\n",
    "                    'lr' : 0.001,  #  learning rate - original model HP\n",
    "                    'optimizer' : 'sgd',  # optimizer - original model setting\n",
    "                    'momentum' : 0.9,  # SGD momentum - original model HP\n",
    "                    'dropout' : 0.5,  # dropout probability - original model HP\n",
    "                    'patience' : 20  # We will train up to 20 epochs without early stopping\n",
    "                    } \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# initial attempt\n",
    "estimator = PyTorch(entry_point='main.py',\n",
    "                    source_dir=source_dir,\n",
    "                    dependencies=dependencies,\n",
    "                    role=role,\n",
    "                    instance_count=instance_count,\n",
    "                    instance_type=instance_type,\n",
    "                    framework_version=framework_version,\n",
    "                    py_version='py3',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=session,\n",
    "                    hyperparameters=hyperparameters\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({\n",
    "    'train': metadata['train'],\n",
    "    'val' : metadata['val']},\n",
    "    job_name=job_name,\n",
    "    wait = False)  # set to `False` then we can attach the model to a new estimator later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now move on to training our [EfficientNet base model](./EfficientNets-Base.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
